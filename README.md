# A journey of learning ML

## Videos
**General**
* [But what is a neural network? | Chapter 1, Deep learning](https://youtu.be/aircAruvnKk)
* [Gradient descent, how neural networks learn | Chapter 2, Deep learning](https://youtu.be/IHZwWFHWa-w)
* [What is backpropagation really doing? | Chapter 3, Deep learning](https://youtu.be/Ilg3gGewQ5U)
* [Backpropagation calculus | Chapter 4, Deep learning](https://youtu.be/tIeHLnjs5U8)
* [But what is a convolution?](https://youtu.be/KuXjwB4LzSA) 

**Transformer**
* [Attention mechanism: Overview](https://youtu.be/fjJOgb-E41w)
* [Introduction to Generative AI](https://youtu.be/G2fqAlgmoPo)
* [Introduction to large language models](https://youtu.be/zizonToFXDs)
* [State of GPT | BRK216HFS](https://youtu.be/bZQun8Y4L2At)

**Systems**
* [Deep Learning Systems Courses](dlsyscourse.org)


## Papers
### LLM
**A technique for accelerating LLM inference**
* Response Length Perception and Sequence Scheduling: An LLM-Empowered LLM Inference Pipeline (arxiv) [[paper](https://arxiv.org/abs/2305.13144) | [review](reviews/sequence-scheduling.md)]

**Offloading to utilize memory from CPU and disk**
* FlexGen: High-throughput Generative Inference of Large Language Models with a Single GPU (ICML'23) [[paper](https://arxiv.org/abs/2303.06865) | [review](reviews/flexgen.md)]

**Distributed Inference Systems**
* ORCA: A Distributed Serving System for Transformer-Based Generative Models (OSDI'22) [[paper](https://www.usenix.org/system/files/osdi22-yu.pdf) | [review](reviews/orca.md)]

**Model Parallelism**
* Beta: Statistical Multiplexing with Model Parallelism for Deep Learning Serving [[paper]() | [review](reviews/beta.md)]

**Parallel DL training systems**
* Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning (OSDI'22) [[paper](https://www.usenix.org/system/files/osdi22-zheng-lianmin.pdf) | [review](reviews/alpa.md)]
